# SPDX-License-Identifier: Apache-2.0
# syntax=docker/dockerfile:1.4

# Dockerfile.vllm-prefill-mi300x-nixl
# vLLM Prefill Node for AMD MI300X with NIXL, UCX, and LMCache
# Built from ROCm base (not Habana Gaudi)
#
# Build: docker build -f Dockerfile.vllm-prefill-mi300x-nixl -t vllm-prefill-mi300x-nixl:latest .

FROM rocm/dev-ubuntu-24.04:6.2 AS vllm-prefill-mi300x-nixl

# ——————————————————————————————————————————————————
# Pre‐declare all ENVs so later `ENV foo=$foo…` works without linter errors
ENV LD_LIBRARY_PATH="" \
    PKG_CONFIG_PATH="" \
    CMAKE_PREFIX_PATH="" \
    CPLUS_INCLUDE_PATH="" \
    C_INCLUDE_PATH="" \
    LDFLAGS=""
# ——————————————————————————————————————————————————

ARG ARCH="x86_64"
ARG DEFAULT_PYTHON_VERSION="3.12"
ARG LIBFABRIC_REF="v1.22.x"
ARG UCX_REF="v1.19.x"
ARG ROCM_VER=6.2
ARG UBUNTU_CODENAME=noble

ENV DEBIAN_FRONTEND=noninteractive
ENV HOME=/root
ENV PREFIX=$HOME/.local
ENV TOPDIR=/workspace

# ROCm is typically installed at /opt/rocm (symlink to /opt/rocm-x.y.z)
# Use realpath to resolve symlinks and avoid build issues
ENV ROCM_HOME=/opt/rocm
ENV ROCM_PATH=/opt/rocm
ENV PATH=$PREFIX/bin:$ROCM_HOME/bin:$PATH
ENV LD_LIBRARY_PATH=$PREFIX/lib:$PREFIX/lib64:$PREFIX/lib/ucx:$PREFIX/lib/x86_64-linux-gnu:$ROCM_HOME/lib:$LD_LIBRARY_PATH

# =============================================================================
# Verify ROCm installation
# =============================================================================
RUN if [ ! -d /opt/rocm ]; then \
      echo "ERROR: ROCm not found at /opt/rocm"; \
      exit 1; \
    fi && \
    echo "ROCm found at: /opt/rocm" && \
    ls -la /opt/rocm && \
    if [ -L /opt/rocm ]; then \
      echo "ROCm is a symlink to: $(readlink -f /opt/rocm)"; \
    fi

# =============================================================================
# Install base dependencies (from nixlbase, minus Gaudi-specific)
# =============================================================================
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential git cmake ninja-build \
    autotools-dev automake libtool wget curl pkg-config \
    pybind11-dev libclang-dev libgflags-dev \
    libgrpc-dev libgrpc++-dev libprotobuf-dev \
    libaio-dev liburing-dev protobuf-compiler-grpc \
    libcpprest-dev etcd-client etcd-server \
    libz-dev flex libgtest-dev libcurl4-openssl-dev \
    libssl-dev uuid-dev zlib1g-dev libboost-all-dev \
    libibverbs-dev rdma-core ibverbs-utils libibumad-dev \
    librdmacm-dev ibverbs-providers meson \
    python${DEFAULT_PYTHON_VERSION} python3-pip \
    ca-certificates gpg lsb-release unzip && \
    rm -rf /var/lib/apt/lists/*

# Install AWS CLI
RUN curl -fsSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o /tmp/awscliv2.zip && \
    unzip -q /tmp/awscliv2.zip -d /tmp && \
    /tmp/aws/install && \
    rm -rf /tmp/awscliv2.zip /tmp/aws

# =============================================================================
# Install additional ROCm development packages for MI300X
# =============================================================================
RUN apt-get update && apt-get install -y --no-install-recommends \
    rocm-hip-sdk \
    rocm-hip-runtime \
    rocm-ml-libraries \
    rocm-dev \
    rocm-libs \
    rocm-smi-lib \
    hip-dev \
    hipify-clang && \
    rm -rf /var/lib/apt/lists/*

# Set MI300X environment
ENV HCC_AMDGPU_TARGET=gfx942
ENV HSA_FORCE_FINE_GRAIN_PCIE=1
ENV HIP_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

# =============================================================================
# Build libfabric (without Gaudi support, with verbs)
# =============================================================================
WORKDIR /workspace
RUN if ls libfabric-*.tar.gz 1> /dev/null 2>&1; then \
      echo "Using vendored libfabric tarball"; \
      tar xf libfabric-*.tar.gz && \
      mv libfabric-*/ libfabric/; \
    else \
      echo "libfabric tarball not found. Cloning ${LIBFABRIC_REF}"; \
      git clone -v https://github.com/ofiwg/libfabric.git; \
      cd libfabric && git checkout ${LIBFABRIC_REF}; \
    fi && \
    cd /workspace/libfabric && \
    ./autogen.sh && \
    ./configure --prefix=$PREFIX --enable-verbs --enable-shm --enable-sockets --enable-tcp --with-rocr=/opt/rocm && \
    make -j$(nproc) && make install && ldconfig

# =============================================================================
# Build UCX with ROCm support
# =============================================================================
WORKDIR /workspace
RUN git clone -v https://github.com/openucx/ucx.git && \
    cd ucx && git checkout ${UCX_REF} && \
    ./autogen.sh && \
    ./configure \
      --prefix=$PREFIX \
      --enable-shared \
      --disable-static \
      --disable-doxygen-doc \
      --enable-optimizations \
      --enable-cma \
      --enable-devel-headers \
      --with-verbs \
      --with-rdmacm \
      --with-rocm=/opt/rocm \
      --enable-mt && \
    make -j$(nproc) && make install && ldconfig

# =============================================================================
# Build etcd-cpp-apiv3
# =============================================================================
WORKDIR /workspace
RUN git clone -v https://github.com/etcd-cpp-apiv3/etcd-cpp-apiv3.git && \
    cd etcd-cpp-apiv3 && mkdir build && cd build && \
    cmake .. \
      -DCMAKE_BUILD_TYPE=Release \
      -DCMAKE_INSTALL_PREFIX=$PREFIX \
      -DCPPREST_INCLUDE_DIR=/usr/include \
      -DCPPREST_LIB=/usr/lib/x86_64-linux-gnu/libcpprest.so \
      -DGRPC_GRPC++_LIBRARY=/usr/lib/x86_64-linux-gnu/libgrpc++.so \
      -DGRPC_LIBRARY=/usr/lib/x86_64-linux-gnu/libgrpc.so \
      -DGPR_LIBRARY=/usr/lib/x86_64-linux-gnu/libgpr.so && \
    make -j$(nproc) && make install && ldconfig

# =============================================================================
# Build AWS SDK (copied from current directory)
# =============================================================================
WORKDIR /workspace
COPY aws-sdk-cpp/ /workspace/aws-sdk-cpp/
RUN mkdir -p aws_sdk_build && cd aws_sdk_build && \
    cmake ../aws-sdk-cpp \
      -DCMAKE_BUILD_TYPE=Release \
      -DBUILD_ONLY="s3" \
      -DENABLE_TESTING=OFF \
      -DCMAKE_INSTALL_PREFIX=/usr/local && \
    make -j$(nproc) && make install && ldconfig

# =============================================================================
# Install uv and Rust
# =============================================================================
WORKDIR /workspace
COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/

ENV RUSTUP_HOME=/usr/local/rustup \
    CARGO_HOME=/usr/local/cargo \
    PATH=/usr/local/cargo/bin:$PATH \
    RUST_VERSION=1.86.0 \
    RUSTARCH=${ARCH}-unknown-linux-gnu

RUN wget --tries=3 --waitretry=5 \
      "https://static.rust-lang.org/rustup/archive/1.28.1/${RUSTARCH}/rustup-init" \
      "https://static.rust-lang.org/rustup/archive/1.28.1/${RUSTARCH}/rustup-init.sha256" && \
    sha256sum -c rustup-init.sha256 && \
    chmod +x rustup-init && \
    ./rustup-init -y --no-modify-path --profile minimal \
      --default-toolchain $RUST_VERSION --default-host ${RUSTARCH} && \
    rm rustup-init* && \
    chmod -R a+w $RUSTUP_HOME $CARGO_HOME

# =============================================================================
# Build NIXL
# =============================================================================
WORKDIR /workspace

# Create necessary directories early
RUN mkdir -p $PREFIX/{bin,lib,include}

# Clone NIXL
RUN git clone -v --progress https://github.com/intel-staging/nixl -b obj_dns_fix

# Set up venv for nixl
ENV VIRTUAL_ENV=/workspace/nixl/.venv
RUN --mount=type=cache,target=/root/.cache/uv \
    uv venv $VIRTUAL_ENV --python $DEFAULT_PYTHON_VERSION && \
    uv pip install --upgrade meson pybind11 patchelf msgspec zmq

# Copy requirements if it exists
RUN if [ -f /workspace/nixl/requirements.txt ]; then \
      uv pip install -r /workspace/nixl/requirements.txt; \
    fi

WORKDIR /workspace/nixl

# Set up environment for nixl to find libfabric and etcd-cpp
ENV PKG_CONFIG_PATH=$PREFIX/lib/pkgconfig:$PKG_CONFIG_PATH \
    CPLUS_INCLUDE_PATH=$PREFIX/include:$CPLUS_INCLUDE_PATH \
    C_INCLUDE_PATH=$PREFIX/include:$C_INCLUDE_PATH \
    LDFLAGS="-L$PREFIX/lib $LDFLAGS"

# Build nixl (disable GDS backend as we're not using CUDA/Gaudi)
RUN uv run --active meson setup \
    --wipe \
    --prefix=$PREFIX \
    --buildtype=release \
    -Ddisable_gds_backend=true \
    -Dlibfabric_path=$PREFIX \
    -Ducx_path=$PREFIX \
    builddir .

RUN cd builddir && \
    ninja && \
    ninja install && \
    ldconfig && \
    cd .. && rm -rf builddir

# Install python modules
RUN pip install pandas msgspec pyzmq

# Install NIXL python package
RUN if [ -f /workspace/nixl/requirements.txt ]; then \
      pip install -r /workspace/nixl/requirements.txt; \
    fi
RUN pip install .

# =============================================================================
# Build nixlbench
# =============================================================================
WORKDIR /workspace/nixl/benchmark/nixlbench/
RUN uv run --active meson setup \
    --wipe \
    --prefix=$PREFIX \
    --buildtype=release \
    -Dnixl_path=$PREFIX \
    -Dcudapath_inc='' \
    -Dcudapath_lib='' \
    -Dcudapath_stub='' \
    builddir .

RUN cd builddir && \
    ninja && \
    ninja install && \
    ldconfig

# Verify installation and library paths
RUN ldconfig && \
    echo "Library paths configured:" && \
    echo $LD_LIBRARY_PATH | tr ':' '\n' && \
    echo "Installed binaries:" && \
    ls -la $PREFIX/bin/ || true && \
    echo "Installed libraries:" && \
    find $PREFIX/lib* -name "*.so*" 2>/dev/null | head -10 || true

# =============================================================================
# Install PyTorch with ROCm support
# =============================================================================
RUN pip install --no-cache-dir torch torchvision --index-url https://download.pytorch.org/whl/rocm6.2

# =============================================================================
# Build vLLM with ROCm
# =============================================================================
WORKDIR ${TOPDIR}

# Clone vLLM
RUN git clone -v https://github.com/vllm-project/vllm ${TOPDIR}/vllm
WORKDIR ${TOPDIR}/vllm

# Checkout stable commit (v0.10.0 or as needed)
RUN git checkout v0.10.0 || git checkout main

# Install build requirements (excluding torch)
RUN set -eux; \
    sed '/^torch/d' requirements/build.txt > /tmp/req-no-torch.txt; \
    pip install --no-cache-dir -r /tmp/req-no-torch.txt; \
    rm -f /tmp/req-no-torch.txt

# Patch setup.py to fix runtime environment detection
RUN python3 -c "\
import re; \
content = open('setup.py', 'r').read(); \
content = re.sub(r'raise RuntimeError\(\"Unknown runtime environment\"\)', 'return \"0.10.0+rocm\"', content); \
open('setup.py', 'w').write(content); \
print('Patched setup.py to bypass runtime environment detection')"

# Build vLLM with ROCm
ENV VLLM_TARGET_DEVICE=rocm
ENV VLLM_BUILD_ENVIRONMENT=local
ENV VLLM_INSTALL_PUNICA_KERNELS=1

# Set environment variables inline to ensure they're available during build
RUN export VLLM_TARGET_DEVICE=rocm && \
    export VLLM_BUILD_ENVIRONMENT=local && \
    export VLLM_INSTALL_PUNICA_KERNELS=1 && \
    pip install --no-build-isolation -e .

# =============================================================================
# Install LMCache with ROCm support
# =============================================================================
WORKDIR ${TOPDIR}

RUN pip install boto3 botocore pandas msgspec pyzmq aiofile redis sortedcontainers

# Clone LMCache
RUN git clone --depth=1 -b wip-nixl-obj https://github.com/mmgaggle/LMCache.git ${TOPDIR}/LMCache

WORKDIR ${TOPDIR}/LMCache

# Install build requirements
RUN pip install -r requirements/build.txt || true

# Patch setup.py to skip CUDA/HIP extensions for ROCm-only environment
# This must be done BEFORE pip install attempts to parse setup.py
RUN python3 << 'PATCH_SETUP'
import re

print("Reading setup.py...")
with open('setup.py', 'r') as f:
    content = f.read()

original = content
patches = 0

# Patch 1: Replace the entire cuda_extension function to return empty list
pattern1 = r'def cuda_extension\([^)]*\):.*?(?=\ndef [a-z_]+|class |if __name__|$)'
if re.search(pattern1, content, re.DOTALL):
    content = re.sub(pattern1, 'def cuda_extension(*args, **kwargs):\n    """Disabled for non-CUDA environments"""\n    return []\n\n', content, flags=re.DOTALL)
    patches += 1
    print('✓ Patch 1: Replaced cuda_extension() function')

# Patch 2: Replace cuda_extensions = cuda_extension(...) calls
pattern2 = r'cuda_extensions\s*=\s*cuda_extension\([^)]*\)'
if re.search(pattern2, content):
    content = re.sub(pattern2, 'cuda_extensions = []  # Disabled for ROCm', content)
    patches += 1
    print('✓ Patch 2: Set cuda_extensions = []')

# Patch 3: Replace ext_modules = cuda_extensions
pattern3 = r'ext_modules\s*=\s*cuda_extensions'
if re.search(pattern3, content):
    content = re.sub(pattern3, 'ext_modules = []  # Disabled for ROCm', content)
    patches += 1
    print('✓ Patch 3: Set ext_modules = []')

# Patch 4: Remove "Building CUDA extensions" print
content = re.sub(r'print\(["\']Building CUDA extensions["\']\)', 'print("Skipping CUDA extensions for ROCm")', content)

if patches == 0:
    print('WARNING: No patches applied! Pattern not found in setup.py')
    print('First 50 lines of setup.py:')
    print('\n'.join(content.split('\n')[:50]))
else:
    with open('setup.py', 'w') as f:
        f.write(content)
    print(f'✓ Successfully applied {patches} patches to setup.py')
PATCH_SETUP

# Set CUDA_HOME to a dummy path to avoid errors, even though we're not using it
ENV CUDA_HOME=/opt/rocm
ENV LMCACHE_SKIP_CUDA_BUILD=1

# Install LMCache without CUDA extensions
RUN pip install -e . --no-build-isolation --no-deps || \
    (echo "ERROR: LMCache installation failed after patching. Check setup.py patch." && \
     echo "Continuing without LMCache..." && true)

# Verify LMCache installation
RUN python -c "import lmcache; print(f'LMCache: {lmcache.__version__}')" 2>/dev/null || \
    echo "LMCache not available (will use vLLM prefix caching only)"

# =============================================================================
# NIXL Benchmark Scripts for MI300X
# =============================================================================

# NIXL benchmark script for MI300X (UCX with ROCm)
COPY <<'NIXLBENCH_MI300X' $HOME/.local/bin/nixlbench-mi300x-ucx.sh
#!/usr/bin/env bash
set -euo pipefail

export ETCD=${ETCD:-http://127.0.0.1:2379}
export START=${START:-4096}
export MAX=${MAX:-67108864}
export NITER=${NITER:-1000}
export NTH=${NTH:-4}
export WARM=${WARM:-100}

# UCX with ROCm transport
export UCX_TLS=${UCX_TLS:-rc,rocm,sm,self}
export UCX_NET_DEVICES=${UCX_NET_DEVICES:-mlx5_0:1}
export UCX_IB_GPU_DIRECT_RDMA=yes
export UCX_MEMTYPE_CACHE=n
export UCX_RC_TM_ENABLE=y
export UCX_LOG_LEVEL=error
export NIXL_LOG_LEVEL=${NIXL_LOG_LEVEL:-WARN}

exec "$HOME/.local/bin/nixlbench" \
  --etcd-endpoints "$ETCD" \
  --backend UCX \
  --initiator_seg_type DRAM --target_seg_type DRAM \
  --scheme pairwise --mode SG --op_type WRITE \
  --start_block_size "$START" --max_block_size "$MAX" \
  --num_iter "$NITER" --warmup_iter "$WARM" \
  --num_threads "$NTH"
NIXLBENCH_MI300X

RUN chmod +x $HOME/.local/bin/nixlbench-mi300x-ucx.sh

# NIXL benchmark script for object storage testing
COPY <<'NIXLBENCH_OBJ' $HOME/.local/bin/nixlbench-obj.sh
#!/usr/bin/env bash
set -euo pipefail
export ETCD=${ETCD:-http://127.0.0.1:2379}
export MAX=${MAX:-67108864}
export NITER=${NITER:-1}
export NTH=${NTH:-4}
export BATCHSZ=${BATCHSZ:-16}
export BUFFERSZ=${BUFFERSZ:-17179869184}
export WARM=${WARM:-1}
export OBJ_BUCKET_NAME=${OBJ_BUCKET_NAME:-nixl-bucket}
export OBJ_SCHEME=${OBJ_SCHEME:-http}
export OBJ_REGION=${OBJ_REGION:-us-east-1}
export OBJ_ACCESS_KEY=${OBJ_ACCESS_KEY:-minioadmin}
export OBJ_SECRET_KEY=${OBJ_SECRET_KEY:-minioadmin}
export OBJ_ENDPOINT=${OBJ_ENDPOINT:-http://127.0.0.1:9000}
export OBJ_VIRTUAL_ADDRESSING=${OBJ_VIRTUAL_ADDRESSING:-0}
export NIXL_LOG_LEVEL=${NIXL_LOG_LEVEL:-WARN}
exec "$HOME/.local/bin/nixlbench" \
  --etcd-endpoints "$ETCD" \
  --backend OBJ \
  --obj_bucket_name "$OBJ_BUCKET_NAME" \
  --obj_scheme "$OBJ_SCHEME" \
  --obj_region "$OBJ_REGION" \
  --obj_access_key "$OBJ_ACCESS_KEY" \
  --obj_secret_key "$OBJ_SECRET_KEY" \
  --obj_endpoint_override "$OBJ_ENDPOINT" \
  --obj_use_virtual_addressing "$OBJ_VIRTUAL_ADDRESSING" \
  --num_iter "$NITER" --warmup_iter "$WARM" \
  --num_threads "$NTH" \
  --max_batch_size "$BATCHSZ" \
  --total_buffer_size "$BUFFERSZ"
NIXLBENCH_OBJ

RUN chmod +x $HOME/.local/bin/nixlbench-obj.sh

# UCX localhost benchmarks (from nixlbench)
COPY <<'UCXTCP' $HOME/.local/bin/nixlbench-local-ucxtcp.sh
#!/usr/bin/env bash
set -euo pipefail
sysctl -w net.core.rmem_max=268435456 2>/dev/null || true
sysctl -w net.core.wmem_max=268435456 2>/dev/null || true
sysctl -w net.ipv4.tcp_rmem=4096 131072 268435456 2>/dev/null || true
sysctl -w net.ipv4.tcp_wmem=4096 131072 268435456 2>/dev/null || true
sysctl -w net.core.somaxconn=65536 2>/dev/null || true
sysctl -w net.core.netdev_max_backlog=5000 2>/dev/null || true
sysctl -w net.ipv4.tcp_max_syn_backlog=8192 2>/dev/null || true
export ETCD=${ETCD:-http://127.0.0.1:2379}
export START=${START:-4096}
export MAX=${MAX:-67108864}
export NITER=${NITER:-1000}
export NTH=${NTH:-1}
export WARM=${WARM:-100}
export UCX_TLS=${UCX_TLS:-sm,tcp,self}
export UCX_NET_DEVICES=${UCX_NET_DEVICES:-lo}
export UCX_SOCKADDR_TLS_PRIORITY=${UCX_SOCKADDR_TLS_PRIORITY:-tcp}
export UCX_TCP_SNDBUF=${UCX_TCP_SNDBUF:-2097152}
export UCX_TCP_RCVBUF=${UCX_TCP_RCVBUF:-2097152}
export UCX_TCP_CM_REUSEADDR=${UCX_TCP_CM_REUSEADDR:-y}
export UCX_LOG_LEVEL=error
export NIXL_LOG_LEVEL=${NIXL_LOG_LEVEL:-WARN}
exec "$HOME/.local/bin/nixlbench" \
  --etcd-endpoints "$ETCD" \
  --backend UCX \
  --initiator_seg_type DRAM --target_seg_type DRAM \
  --scheme pairwise --mode SG --op_type WRITE \
  --start_block_size "$START" --max_block_size "$MAX" \
  --num_iter "$NITER" --warmup_iter "$WARM" \
  --num_threads "$NTH"
UCXTCP

RUN chmod +x $HOME/.local/bin/nixlbench-local-ucxtcp.sh

# =============================================================================
# Entrypoint and Health Check
# =============================================================================

COPY <<'ENTRYPOINT' /entrypoint-mi300x-nixl.sh
#!/bin/bash
set -e

echo "=== vLLM Prefill Node (AMD MI300X) with NIXL ==="
echo "ROCm Version: $(cat /opt/rocm/.info/version 2>/dev/null || echo 'unknown')"
echo "Visible GPUs: ${HIP_VISIBLE_DEVICES:-all}"

# Verify ROCm
rocm-smi --showproductname 2>/dev/null || echo "Warning: rocm-smi not available"

# Verify UCX transports
echo "UCX Transports:"
ucx_info -d | grep -E "(Transport|Device)" | head -20 || echo "Warning: ucx_info not available"

# Verify libraries
echo "Checking libraries..."
ldconfig
ldd $(which python) | grep -E "(libfabric|ucx)" || echo "Warning: libfabric/ucx not linked"

# Verify NIXL
nixlbench --help 2>&1 | head -5 || echo "Warning: nixlbench not available"

exec "$@"
ENTRYPOINT

RUN chmod +x /entrypoint-mi300x-nixl.sh

HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

WORKDIR /workspace

ENTRYPOINT ["/entrypoint-mi300x-nixl.sh"]
CMD ["python", "-m", "vllm.entrypoints.openai.api_server", "--help"]
